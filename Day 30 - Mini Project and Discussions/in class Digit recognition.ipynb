{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist.load_data()\n",
    "# print(data)\n",
    "type(data)\n",
    "\n",
    "len(data[0])\n",
    "\n",
    "data[0][0].shape\n",
    "\n",
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple unpacking\n",
    "x,y = ((1,2,3),(10,20,30))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking tuples\n",
    "#------data[0]----    -----data[1]---\n",
    "# data[0][0]    data[0][1]     data[1][0]   data[1][1]\n",
    "( X_train   ,    y_train ),     (X_test,       y_test   ) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0][0]\n",
    "# an image in data\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, linewidth=150)\n",
    "data[0][0][50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0,   0,   0,   0],\n",
    "     [0,   1,   0,   0],\n",
    "     [0,   1,   0,   0],\n",
    "     [0,   0,   0,   0]]\n",
    "\n",
    "# 15 x 15 \n",
    "x = [[0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0],\n",
    "     [0,   0,   0,   0,   0,   0,   0,   0,  0,   0,   0,   0,   0,   0,   0,   0]]\n",
    "\n",
    "\n",
    "# 8 x 8 image\n",
    "x = np.array([[0,0,0,0,0,0,0,0],\n",
    "     [1,1,0,0,0,0,1,1],\n",
    "     [1,0,10,0,0,1,0,1],\n",
    "     [1,0,0,1,1,0,0,1],\n",
    "     [1,0,0,15,1,0,0,1],\n",
    "     [1,0,0,1,1,0,0,1],\n",
    "     [1,0,0,0,0,0,0,1],\n",
    "     [0,0,0,0,0,0,0,0]])\n",
    "\n",
    "\n",
    "plt.imshow(x, cmap='grey')\n",
    "plt.title('my first image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[0][0][12]\n",
    "\n",
    "plt.imshow(img, cmap='grey')\n",
    "\n",
    "# grey scale images - intensity of black \n",
    "# 255 levels of intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### the maximum value in the matrix becomes the \n",
    "- max - white\n",
    "- shades of grey - intensities of black\n",
    "- min - black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the pixels to be between 0 and 1 (math is easier for AI this way)\n",
    "X_train, X_test = X_train/ 255, X_test/ 255\n",
    "\n",
    "imgX = X_train[12]\n",
    "imgX\n",
    "plt.imshow(imgX, cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train # 60 K images   # 28 X 28\n",
    "# y_train # 60K label     # 1 3 5 6 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=150, edgeitems=150)\n",
    "print(X_train[12].round().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[12].round().astype(int), cmap='grey')\n",
    "\n",
    "sns.heatmap(X_train[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## use TF to build a CNN model to do stufffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    # input layer\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    # hidden layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # output layer\n",
    "    tf.keras.layers.Dense(10, activation='softmax') # loudest voice - the confidence is the most\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions[10].max() # max value\n",
    "\n",
    "predictions[10].argmax() # index of max value\n",
    "\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### take one image, use our model, and make a prediction???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_12 = model.predict(np.expand_dims(X_test[12], 0)) # predict method expects 3D arrays\n",
    "pred_12.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[12].shape\n",
    "\n",
    "np.expand_dims(X_test[12],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_labels)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## test my own input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # Tool to open images\n",
    "\n",
    "# 1. CHANGE THIS to your actual filename!\n",
    "filename = \"testimg2.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Open the image and convert to Grayscale (Black and White)\n",
    "img = Image.open(filename).convert('L')\n",
    "\n",
    "# 3. Resize it to 28x28 pixels (the exact size the AI learned)\n",
    "img = img.resize((28, 28))\n",
    "\n",
    "# 4. Turn the image into numbers\n",
    "img_array = np.array(img)\n",
    "\n",
    "# 5. Flip colors (If you drew black ink on white paper, we must flip it)\n",
    "# AI needs white ink on black background!\n",
    "img_array = 255 - img_array \n",
    "\n",
    "# 6. Normalize (Scale numbers to be between 0 and 1)\n",
    "img_array = img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_array.reshape(1, 28, 28))\n",
    "print(f\"I think this digit is a: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    \n",
    "    # Layer 1: Find 32 different features (edges, lines)\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Layer 2: Find more complex patterns\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Layer 3: Prevent memorization (Dropout)\n",
    "    layers.Dropout(0.25), \n",
    "    \n",
    "    # Layer 4: Final decision making\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax') # 10 outputs for digits 0-9\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- STEP 3: TRAINING ---\n",
    "print(\"Training the Awesome Model... (Wait for 3 epochs)\")\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_array.reshape(1, 28, 28))\n",
    "print(f\"I think this digit is a: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # Tool to open images\n",
    "\n",
    "# 1. CHANGE THIS to your actual filename!\n",
    "filename = \"numberplate.png\" \n",
    "\n",
    "\n",
    "# 2. Open the image and convert to Grayscale (Black and White)\n",
    "img = Image.open(filename).convert('L')\n",
    "\n",
    "# 3. Resize it to 28x28 pixels (the exact size the AI learned)\n",
    "img = img.resize((28, 28))\n",
    "\n",
    "# 4. Turn the image into numbers\n",
    "img_array = np.array(img)\n",
    "\n",
    "# 5. Flip colors (If you drew black ink on white paper, we must flip it)\n",
    "# AI needs white ink on black background!\n",
    "img_array = 255 - img_array \n",
    "\n",
    "# 6. Normalize (Scale numbers to be between 0 and 1)\n",
    "img_array = img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### NUMBER PLATE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# --- 1. TRAIN A STRONGER BRAIN ---\n",
    "# We use a deeper CNN with \"Dropout\" to prevent mistakes\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2), # Helps the AI not \"over-memorize\"\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Training high-accuracy model...\")\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. THE ADVANCED RECOGNITION ---\n",
    "image = cv2.imread('numberplate.png')\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: numberplate.png not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Open CV to do everything now     \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use Gaussian Blur to remove 'noise' or 'grain'\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Adaptive Thresholding helps in different lighting\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY_INV, 11, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "predictions = []\n",
    "\n",
    "for ctr in contours:\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "    \n",
    "    # Only process shapes that look like digits (ignores small noise)\n",
    "    if h > 15: \n",
    "        # 1. Extract the digit\n",
    "        roi = thresh[y:y+h, x:x+w]\n",
    "        \n",
    "        # 2. THE SECRET SAUCE: Add padding so it's not squashed\n",
    "        # We add a 20% border around the digit\n",
    "        pad = int(max(w, h) * 0.2)\n",
    "        roi = cv2.copyMakeBorder(roi, pad, pad, pad, pad, \n",
    "                                 cv2.BORDER_CONSTANT, value=0)\n",
    "        \n",
    "        # 3. Resize to 28x28 and Normalize\n",
    "        roi = cv2.resize(roi, (28, 28))\n",
    "        roi = roi.astype('float32') / 255.0\n",
    "        \n",
    "        # 4. Predict\n",
    "        test_input = roi.reshape(1, 28, 28, 1)\n",
    "        pred = model.predict(test_input, verbose=0)\n",
    "        digit = np.argmax(pred)\n",
    "        predictions.append(str(digit))\n",
    "        \n",
    "        # Draw visual feedback\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, str(digit), (x, y-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Display\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Highly Accurate Detection: {''.join(predictions)}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
